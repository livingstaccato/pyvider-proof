                             Pyvider
                           March 2025


Abstract

   This document specifies the architecture and implementation 
   requirements for Pyvider, a Python-based framework for developing
   Terraform providers. It describes the core component system,
   schema architecture, protocol integration, and operational
   considerations necessary for compliant implementation.


Status of This Memo

   This document is a framework specification for Pyvider implementations.
   It does not represent an Internet Standards Track specification.

   Distribution of this memo is unlimited.


Copyright Notice

   Copyright (c) 2025 The Pyvider Authors. All rights reserved.


Table of Contents

   1. Introduction ................................................ 2
      1.1. Terminology ............................................ 3
      1.2. Requirements Language .................................. 4
   2. Overall Architecture ....................................... 4
      2.1. Design Principles ...................................... 5
      2.2. Component Hierarchy .................................... 6
   3. The Component System ....................................... 7
      3.1. Component Registry ..................................... 7
      3.2. Component Types ........................................ 8
      3.3. Registration Mechanisms ................................ 10
      3.4. Component Discovery .................................... 12
   4. Schema Architecture ........................................ 13
      4.1. Schema Definitions ..................................... 13
      4.2. Type System ............................................ 16
      4.3. Schema Validation ...................................... 19
      4.4. Schema Conversion ...................................... 20
   5. Resource Implementation .................................... 21
      5.1. Resource Lifecycle ..................................... 21
      5.2. State Management ....................................... 24
      5.3. Context Model .......................................... 25
   6. Protocol Integration ....................................... 26
      6.1. Protocol Handlers ...................................... 26
      6.2. Type Conversion ........................................ 30
      6.3. Protocol Security ...................................... 32
   7. Implementation Requirements ................................ 33
      7.1. Core Requirements ...................................... 33
      7.2. Optional Extensions .................................... 34
   8. Security Considerations .................................... 35
   9. Testing and Validation ..................................... 37
   10. References ................................................ 38
   11. Authors' Addresses ........................................ 39


1. Introduction

   Terraform has become a standard tool for defining infrastructure as
   code. While the official SDK for developing Terraform providers is
   written in Go, many organizations have significant investments in
   Python for their infrastructure management. The Pyvider framework
   bridges this gap by offering a Python-based approach to Terraform
   provider development.

   This document specifies the architecture and implementation
   requirements for Pyvider, ensuring compatibility with the Terraform
   Plugin Protocol v6 while providing a Pythonic developer experience.
   It is intended for implementers of the Pyvider framework and
   developers creating Terraform providers using Pyvider.

   Pyvider follows a component-based architecture where resources, data
   sources, functions, and capabilities are registered with a central
   hub. These components implement the required interfaces for Terraform
   integration and are automatically discovered and exposed through the
   provider schema.

1.1. Terminology

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
   document are to be interpreted as described in RFC 2119.

   Component:
      Any registrable entity in Pyvider that participates in the 
      Terraform provider ecosystem, including resources, data sources,
      functions, and capabilities.

   Resource:
      A component that manages infrastructure objects with create, read,
      update, and delete (CRUD) operations.

   Data Source:
      A component that provides read-only data from external systems.

   Function:
      A component that implements custom operations available in
      Terraform configurations.

   Capability:
      A component that represents a provider feature that can be
      conditionally enabled.

   Schema:
      A definition of the structure, types, and validation rules for
      Terraform configurations.

   Hub:
      The central registry for components in a Pyvider provider.

   Cty Type:
      A type in the Cty type system that maps to Terraform's type system.

   Handler:
      A function that processes RPC calls from the Terraform Plugin
      Protocol.

2. Overall Architecture

   Pyvider implements a layered architecture with clear separation of
   concerns between the component system, schema definitions, resource
   implementations, and protocol integration.

                           +---------------+
                           | Terraform CLI |
                           +-------+-------+
                                   |
                                   | gRPC Plugin Protocol v6
                                   |
   +----------------------------+  |  +---------------------+
   |     Pyvider Framework      |  |  |                     |
   |                            |  |  |                     |
   | +------------------------+ |  |  |                     |
   | |    Protocol Layer      |<----+  |    Provider        |
   | +----------+-------------+ |     |    Implementation   |
   |            |               |     |                     |
   | +----------v-------------+ |     |                     |
   | |    Component System    |<----->|                     |
   | +----------+-------------+ |     |                     |
   |            |               |     |                     |
   | +----------v-------------+ |     |                     |
   | |    Schema System       |<----->|                     |
   | +----------+-------------+ |     |                     |
   |            |               |     |                     |
   | +----------v-------------+ |     |                     |
   | |    Resource System     |<----->|                     |
   | +------------------------+ |     |                     |
   |                            |     |                     |
   +----------------------------+     +---------------------+

2.1. Design Principles

   Pyvider follows these core design principles:

   1. Pythonic API:
      The framework MUST provide an API that feels natural to Python
      developers, leveraging language features like decorators, context
      managers, and async/await.

   2. Type Safety:
      Pyvider MUST use Python's type annotations to ensure type safety
      and provide proper conversion to Terraform's type system.

   3. Minimal Boilerplate:
      Implementations SHOULD minimize boilerplate code through factory
      functions, decorators, and sensible defaults.

   4. Protocol Compatibility:
      The framework MUST maintain full compatibility with the Terraform
      Plugin Protocol v6.

   5. Extensibility:
      The architecture SHOULD allow for extensions and customizations
      without modifying the core framework.

   6. Performance:
      Implementations MUST consider performance implications, especially
      for protocol conversions and resource operations.

   7. Security:
      The framework MUST handle authentication, authorization, and
      sensitive data appropriately.

2.2. Component Hierarchy

   The Pyvider component hierarchy defines the relationships between
   different parts of the framework:

   1. Provider:
      The top-level component that initializes and manages the plugin.

   2. Resources:
      Components that implement CRUD operations for managed infrastructure.

   3. Data Sources:
      Components that retrieve and present data from external systems.

   4. Functions:
      Components that implement custom operations for use in Terraform
      configurations.

   5. Capabilities:
      Components that represent provider features that can be
      conditionally enabled.

   All components MUST be registered with the Hub registry to be
   discoverable and usable by the provider.

3. The Component System

   The component system forms the backbone of Pyvider, providing a
   unified registration mechanism, lifecycle management, and dynamic
   discovery for all provider elements.

3.1. Component Registry

   The Hub serves as the central registry for all components in a
   Pyvider provider. It MUST provide the following functionality:

   1. Registration of components by type and name
   2. Retrieval of components for handling Terraform operations
   3. Schema collection for provider configuration
   4. Component discovery for automatic registration

   The Hub implementation MUST be a singleton accessible throughout the
   provider to ensure consistent component registration and retrieval.

   Example implementation:

```python
@attrs.define
class ComponentRegistry:
    """Multi-dimensional registry for managing components by type and name."""
    
    registry: dict[str, dict[str, Callable]] = attrs.field(
        factory=dict,
        metadata={"description": "Two-level dictionary of components"}
    )
    
    def register(self, component_type: str, name: str, component: Callable) -> None:
        """Register a component under a specific type and name."""
        if component_type not in self.registry:
            self.registry[component_type] = {}
            
        self.registry[component_type][name] = component
        
    def get_component(self, component_type: str, name: str) -> Optional[Callable]:
        """Retrieve a component by type and name."""
        return self.registry.get(component_type, {}).get(name)
        
    def list_components(self, component_type: Optional[str] = None) -> dict:
        """List all registered components, optionally filtered by type."""
        if component_type:
            return {component_type: self.registry.get(component_type, {})}
        return self.registry
```

3.2. Component Types

   Pyvider defines several core component types, each with specific
   interfaces and lifecycle requirements:

3.2.1. Resources

   Resources represent managed infrastructure elements with a full
   lifecycle. Resource implementations MUST:

   1. Extend the BaseResource class
   2. Define config and state types
   3. Implement schema definition
   4. Implement required lifecycle methods (validate, read, plan, apply)
   5. Handle error conditions appropriately

   Example resource interface:

```python
class BaseResource(Generic[ResourceType, StateType, ConfigType], ABC):
    """Base class for resource implementations."""
    
    @abstractmethod
    async def validate(self, config: ConfigType) -> None:
        """Validate resource configuration."""
        
    @abstractmethod
    async def read(self, ctx: ResourceContext[ConfigType, StateType]) -> StateType:
        """Read resource state."""
        
    @abstractmethod
    async def plan(
        self, ctx: ResourceContext[ConfigType, StateType]
    ) -> tuple[StateType, bytes]:
        """Plan resource changes."""
        
    @abstractmethod
    async def apply(
        self, ctx: ResourceContext[ConfigType, StateType]
    ) -> tuple[StateType, bytes]:
        """Apply resource changes."""
```

3.2.2. Data Sources

   Data sources provide read-only information from external systems.
   Data source implementations MUST:

   1. Define schema through get_schema method
   2. Implement read method
   3. Optionally implement validate method

   Example data source interface:

```python
class DataSourceProtocol(Protocol):
    """Protocol defining data source requirements."""
    
    @staticmethod
    def get_schema() -> Any:
        """Get the data source schema."""
        
    async def read(self, ctx: ResourceContext) -> Dict[str, Any]:
        """Read data from the data source."""
        
    async def validate(self, config: Any) -> List[str]:
        """Validate data source configuration."""
```

3.2.3. Functions

   Functions provide custom operations for use in Terraform
   configurations. Function implementations MUST:

   1. Define input parameters and return type
   2. Be decorated with @register_function
   3. Handle input validation and error cases

   Example function registration:

```python
@register_function(
    name="example_format",
    summary="Format a string with placeholders",
    description="Formats a string by replacing placeholders with values.",
    param_descriptions={
        "template": "String template with {0}, {1}, etc. placeholders",
        "values": "List of values to insert into the template"
    }
)
def format_string(template: CtyString, values: CtyList) -> CtyString:
    """Format a string using placeholders."""
    try:
        # Extract values and format string
        str_values = [str(v) for v in values]
        return template.format(*str_values)
    except Exception as e:
        raise FunctionError(f"String formatting failed: {e}")
```

3.2.4. Capabilities

   Capabilities represent provider features that can be conditionally
   enabled. Capability implementations MUST:

   1. Implement the Capability protocol
   2. Define schema through get_schema method
   3. Implement validate method
   4. Implement is_configured method

   Example capability interface:

```python
class Capability(Protocol):
    """Protocol defining capability requirements."""
    
    def get_schema(self) -> Schema:
        """Get the capability schema."""
        
    async def validate(self, config: Dict[str, Any]) -> List[str]:
        """Validate capability configuration."""
        
    def is_configured(self, config: Dict[str, Any]) -> bool:
        """Check if the capability is configured."""
```

3.3. Registration Mechanisms

   Pyvider MUST provide multiple registration mechanisms to accommodate
   different implementation patterns and organization preferences:

3.3.1. Decorator Registration

   Component registration via decorators SHOULD be the primary mechanism
   for most implementations. The framework MUST provide decorators for
   each component type:

```python
@register_resource("example_resource")
class ExampleResource(BaseResource):
    """Example resource implementation."""
    
@register_data_source("example_data")
class ExampleDataSource:
    """Example data source implementation."""
    
@register_function(
    name="example_function",
    summary="Example function",
    description="An example function implementation."
)
def example_function(input: CtyString) -> CtyString:
    """Example function implementation."""
    
@register_capability("example_capability")
class ExampleCapability(Capability):
    """Example capability implementation."""
```

3.3.2. Direct Registration

   The framework MUST also support direct registration through the Hub
   API for cases where decorator registration is not appropriate:

```python
# Register a resource
hub.register("resource", "example_resource", ExampleResource)

# Register a data source
hub.register("data_source", "example_data", ExampleDataSource)

# Register a function
hub.register("function", "example_function", example_function)

# Register a capability
hub.register("capability", "example_capability", ExampleCapability)
```

3.3.3. Auto-Discovery

   The framework SHOULD support automatic discovery of components through
   module scanning. This mechanism is OPTIONAL but RECOMMENDED for larger
   provider implementations:

```python
# Discover components from modules
discovery = ComponentDiscovery(hub)
await discovery.discover_all()
```

   Implementation details of component discovery are left to specific
   implementations, but they SHOULD follow these guidelines:

   1. Scan specified modules for component classes and functions
   2. Identify components through markers like specific base classes
   3. Register discovered components with the Hub
   4. Provide appropriate logging for discovery process

3.4. Component Discovery

   The component discovery mechanism enables automatic registration of
   components from specified modules. While optional, this feature is
   valuable for larger provider implementations with many components.

   The discovery process SHOULD:

   1. Scan specified modules for component classes and functions
   2. Identify components through markers (base classes, attributes)
   3. Register discovered components with the Hub
   4. Provide appropriate logging for discovery process

   Example discovery implementation:

```python
class ComponentDiscovery:
    """Component discovery and registration."""

    def __init__(self, registry, auto_register: bool = False):
        self.registry = registry
        self.auto_register = auto_register
        self._processed_components = set()

    async def discover_all(self) -> None:
        """Discover and register all components."""
        logger.info("Starting component discovery process")
        
        # Example: discover from components directory
        for finder, name, is_pkg in pkgutil.walk_packages(["components"], 
                                                         prefix="components."):
            if is_pkg:
                continue
                
            try:
                module = importlib.import_module(name)
                await self._process_module(module)
            except Exception as e:
                logger.error(f"Failed to import module '{name}': {e}")
                
        logger.info("Component discovery process completed")
        
    async def _process_module(self, module):
        """Process and register components in a module."""
        for name, obj in inspect.getmembers(module):
            # Check for component markers and register if found
            if hasattr(obj, "_is_registered_resource"):
                self._register_resource(obj)
            elif hasattr(obj, "_is_registered_data_source"):
                self._register_data_source(obj)
            # ... and so on for other component types
```

4. Schema Architecture

   The schema architecture defines how Terraform configuration structures
   are represented in Pyvider. A well-designed schema system is critical
   for proper validation, serialization, and protocol integration.

4.1. Schema Definitions

   Schema definitions in Pyvider MUST provide a clear mapping between
   Python structures and Terraform schema components. The schema system
   MUST support:

   1. Attribute definitions with type, required/optional, and metadata
   2. Nested block definitions for complex structures
   3. Schema validation and error reporting
   4. Conversion to Terraform protocol format

4.1.1. Schema Structure

   The schema structure follows a hierarchical model:

```
SchemaDefinition
├── attributes: Dict[str, SchemaAttribute]
│   └── SchemaAttribute
│       ├── name: str
│       ├── type: CtyType
│       ├── required: bool
│       ├── optional: bool
│       ├── computed: bool
│       ├── sensitive: bool
│       └── description: str
└── blocks: Dict[str, NestedBlock]
    └── NestedBlock
        ├── name: str
        ├── block: SchemaBlock
        │   └── attributes: List[SchemaAttribute]
        ├── nesting_mode: BlockNestingMode
        ├── min_items: Optional[int]
        └── max_items: Optional[int]
```

4.1.2. Schema Creation Patterns

   Pyvider MUST provide multiple approaches to schema creation to
   accommodate different implementation preferences and complexity levels:

   1. Factory Functions (Recommended):

```python
from pyvider.schema.pvfactory import (
    a_str, a_num, a_bool, a_map, a_list, s_resource
)

schema = s_resource({
    "name": a_str(required=True, description="Resource name"),
    "count": a_num(default=1, description="Instance count"),
    "enabled": a_bool(default=True),
    "tags": a_map(a_str(), description="Resource tags"),
    "items": a_list(a_str(), description="Item list")
})
```

   2. Schema Definition API:

```python
from pyvider.schema.definition import (
    SchemaDefinition, SchemaAttribute, SchemaBlock
)
from pyvider.cty import CtyString, CtyNumber, CtyBool

schema = SchemaDefinition(
    attributes={
        "name": SchemaAttribute(
            name="name",
            type=CtyString(),
            required=True,
            description="Resource name"
        ),
        "count": SchemaAttribute(
            name="count",
            type=CtyNumber(),
            default=1,
            description="Instance count"
        )
    },
    description="Example schema"
)
```

   3. Base Schema Classes:

```python
from pyvider.schema.base import Schema, Block, Attribute
from pyvider.schema.types import SchemaType

schema = Schema(
    version=1,
    block=Block(
        attributes=[
            Attribute(
                name="name",
                type=SchemaType.STRING,
                required=True,
                description="Resource name"
            )
        ],
        description="Resource block"
    )
)
```

4.1.3. Nested Blocks

   The schema system MUST support nested blocks for complex structures.
   Nested blocks MUST support all Terraform nesting modes:

   1. SINGLE: Block appears exactly once or not at all
   2. LIST: Block appears as a list of objects
   3. MAP: Block appears as a map of objects
   4. SET: Block appears as a set of objects

   Example nested block definition:

```python
from pyvider.schema.blocks import (
    b_main, b_nested, b_list, b_map, b_set
)

# Main block with nested timeouts block
schema = s_resource({
    "name": a_str(required=True),
    "timeouts": b_nested(
        "timeouts",
        {
            "create": a_num(default=60),
            "delete": a_num(default=60)
        }
    ),
    "network_interfaces": b_list(
        "network_interface",
        {
            "subnet_id": a_str(required=True),
            "ip_address": a_str()
        },
        min_items=1,
        max_items=5
    )
})
```

4.2. Type System

   The Pyvider type system maps Python types to Terraform's type system
   through the Cty interface. This mapping MUST ensure type safety,
   proper validation, and correct serialization.

4.2.1. Cty Types

   The Cty type system MUST provide implementations for all Terraform
   types:

   1. Primitive Types:
      - CtyString: String values
      - CtyNumber: Numeric values (integers and floats)
      - CtyBool: Boolean values

   2. Collection Types:
      - CtyList: Ordered list of elements (same type)
      - CtyMap: Key-value mapping (string keys, same-type values)
      - CtySet: Unordered collection of unique elements

   3. Structural Types:
      - CtyObject: Object with named attributes of possibly different types
      - CtyDynamic: Type-flexible value for runtime determination

   Example Cty type usage:

```python
from pyvider.cty import (
    CtyString, CtyNumber, CtyBool,
    CtyList, CtyMap, CtySet,
    CtyObject, CtyDynamic
)

# String type
string_type = CtyString()

# Number type
number_type = CtyNumber()

# Boolean type
bool_type = CtyBool()

# List of strings
list_type = CtyList(element_type=CtyString())

# Map with string values
map_type = CtyMap(key_type=CtyString(), value_type=CtyString())

# Set of numbers
set_type = CtySet(element_type=CtyNumber())

# Object type
object_type = CtyObject(attribute_types={
    "name": CtyString(),
    "age": CtyNumber()
})

# Dynamic type
dynamic_type = CtyDynamic()
```

4.2.2. Element Type Preservation

   The Cty type system MUST preserve element type information for
   collection types. This is critical for proper schema validation and
   Terraform protocol compatibility.

   Example element type preservation:

```python
# Create a list of strings attribute
names = a_list(a_str())

# Element type information is preserved
assert names.ctype.element_type.__class__ == CtyString

# Create a map with string values
tags = a_map(a_str())

# Value type information is preserved
assert tags.ctype.value_type.__class__ == CtyString
```

4.2.3. Type Conversion

   The Cty type system MUST provide methods for converting between Python
   values and Terraform values:

   1. Python to Cty: Convert Python values to Cty representations
   2. Cty to Python: Convert Cty values to Python representations
   3. Cty to Protocol: Convert Cty types to Terraform protocol types

   Example type conversion:

```python
# Convert Python value to Cty
python_value = "example"
cty_value = CtyString().from_python(python_value)

# Convert Cty value to Python
python_value_again = cty_value.to_python()
assert python_value == python_value_again

# Convert Cty type to protocol bytes
proto_type = get_proto_type_bytes(CtyString())
assert proto_type == b'"string"'
```

4.3. Schema Validation

   Schema validation is a critical component of the Pyvider framework.
   Validation occurs in two contexts:

   1. Schema Definition Validation: Ensuring the schema itself is valid
   2. Value Validation: Checking values against the schema

4.3.1. Schema Definition Validation

   Schema definitions MUST be validated for correctness:

   1. Attribute names MUST be valid identifiers
   2. Attribute types MUST be valid Cty types
   3. Nested blocks MUST have valid names and structures
   4. Required and optional flags MUST not conflict

   Example schema validation:

```python
def validate_schema_definition(schema: SchemaDefinition) -> List[str]:
    """Validate a schema definition."""
    errors = []
    
    # Check for valid version
    if schema.version < 1:
        errors.append("Schema version must be at least 1")
    
    # Validate attributes
    for name, attr in schema.attributes.items():
        if not name.isidentifier():
            errors.append(f"Invalid attribute name: {name}")
        
        if attr.required and attr.optional:
            errors.append(f"Attribute {name} cannot be both required and optional")
    
    # Validate blocks
    for name, block in schema.blocks.items():
        if not name.isidentifier():
            errors.append(f"Invalid block name: {name}")
            
        # Validate min/max items
        if block.min_items is not None and block.min_items < 0:
            errors.append(f"Block {name} min_items cannot be negative")
            
        if (block.min_items is not None and block.max_items is not None and 
            block.max_items < block.min_items):
            errors.append(f"Block {name} max_items cannot be less than min_items")
    
    return errors
```

4.3.2. Value Validation

   Values MUST be validated against schema definitions:

   1. Required attributes MUST be present
   2. Values MUST match their declared types
   3. Nested blocks MUST have valid structures
   4. List/set/map cardinality MUST respect min/max items

   Example value validation:

```python
async def validate_schema(schema: SchemaDefinition, config: Dict[str, Any]) -> List[str]:
    """Validate configuration against schema."""
    errors = []
    
    # Check if config is a dictionary
    if not isinstance(config, dict):
        errors.append("Configuration must be a dictionary")
        return errors
    
    # Check for required attributes
    for name, attr in schema.attributes.items():
        if attr.required and name not in config:
            errors.append(f"Required attribute '{name}' is missing")
    
    # Validate attribute values
    for name, value in config.items():
        # Check if attribute exists in schema
        if name in schema.attributes:
            attr = schema.attributes[name]
            try:
                # Use Cty type to validate value
                attr.type.validate(value)
            except Exception as e:
                errors.append(f"Invalid value for '{name}': {e}")
    
    return errors
```

4.4. Schema Conversion

   Schema definitions MUST be convertible to Terraform protocol format
   for provider registration and operation. The schema adapter is
   responsible for this conversion.

   Example schema conversion:

```python
def schema_to_proto(schema: SchemaDefinition) -> ProtoSchema:
    """Convert schema definition to protobuf format."""
    # Convert attributes
    proto_attrs = []
    for attr in schema.attributes.values():
        proto_attr = ProtoSchema.Attribute(
            name=attr.name,
            type=get_proto_type_bytes(attr.type),
            description=attr.description,
            required=attr.required,
            optional=attr.optional,
            computed=attr.computed,
            sensitive=attr.sensitive,
            description_kind=ProtoStringKind.PLAIN
        )
        proto_attrs.append(proto_attr)
    
    # Create block
    proto_block = ProtoSchema.Block(
        attributes=proto_attrs,
        description=schema.description,
        description_kind=ProtoStringKind.PLAIN
    )
    
    # Create schema
    return ProtoSchema(
        version=schema.version,
        block=proto_block
    )
```

5. Resource Implementation

   Resources are the primary components managed by Terraform. They
   represent infrastructure elements with create, read, update, and
   delete (CRUD) operations.

5.1. Resource Lifecycle

   Resource implementations MUST follow the Terraform lifecycle model:

   1. Read: Get the current state of the resource
   2. Plan: Determine changes needed based on configuration and state
   3. Apply: Make changes to create, update, or delete the resource

5.1.1. Resource Base Class

   All resources MUST extend the BaseResource class or implement an
   equivalent interface:

```python
class BaseResource(Generic[ResourceType, StateType, ConfigType], ABC):
    """Base class for resource implementations."""
    
    @abstractmethod
    async def validate(self, config: ConfigType) -> None:
        """Validate resource configuration."""
        await self._validate_schema(config)
        await self.validate_config(config)
    
    @abstractmethod
    async def read(self, ctx: ResourceContext[ConfigType, StateType]) -> StateType:
        """Read resource state."""
        async with self._lock:
            self._lifecycle.transition_to(ResourceState.UNKNOWN, "read")
            try:
                return await self._read(ctx)
            except Exception as e:
                self._lifecycle.error = str(e)
                raise ResourceOperationError(f"Read operation failed: {e}")
    
    @abstractmethod
    async def plan(
        self, ctx: ResourceContext[ConfigType, StateType]
    ) -> tuple[StateType, bytes]:
        """Plan resource changes."""
        async with self._lock:
            self._lifecycle.transition_to(ResourceState.PLANNED, "plan")
            try:
                await self.validate(ctx.config)
                return await self._plan(ctx)
            except Exception as e:
                self._lifecycle.error = str(e)
                raise ResourceOperationError(f"Plan operation failed: {e}")
    
    @abstractmethod
    async def apply(
        self, ctx: ResourceContext[ConfigType, StateType]
    ) -> tuple[StateType, bytes]:
        """Apply resource changes."""
        async with self._lock:
            state_type = (ResourceState.CREATING if not ctx.state 
                         else ResourceState.UPDATING)
            self._lifecycle.transition_to(state_type, "apply")
            try:
                return await self._apply(ctx)
            except Exception as e:
                self._lifecycle.error = str(e)
                raise ResourceOperationError(f"Apply operation failed: {e}")
```

5.1.2. Resource States

   Resources MUST track their state throughout the lifecycle:

```python
class ResourceState(Enum):
    """Resource lifecycle states."""
    UNKNOWN = "UNKNOWN"
    PLANNED = "PLANNED"
    CREATING = "CREATING"
    CREATED = "CREATED"
    UPDATING = "UPDATING"
    DELETING = "DELETING"
    DELETED = "DELETED"
    FAILED = "FAILED"

@dataclass
class ResourceLifecycle:
    """Tracks resource lifecycle state."""
    state: ResourceState = ResourceState.UNKNOWN
    last_operation: Optional[str] = None
    last_updated: Optional[datetime] = None
    error: Optional[str] = None

    def transition_to(self, state: ResourceState, operation: str) -> None:
        """Transition to a new state."""
        self.state = state
        self.last_operation = operation
        self.last_updated = datetime.utcnow()
```

5.1.3. Resource Registration

   Resources MUST be registered with the Hub to be discoverable:

```python
@register_resource("example_resource")
class ExampleResource(BaseResource["example_resource", ExampleState, ExampleConfig]):
    """Example resource implementation."""
    
    @staticmethod
    def get_schema():
        """Define the resource schema."""
        return s_resource({
            # Schema definition
        })
    
    async def validate_config(self, config: ExampleConfig) -> None:
        """Validate resource configuration."""
        # Custom validation logic
        
    async def _read(self, ctx: ResourceContext[ExampleConfig, ExampleState]) -> ExampleState:
        """Read current resource state."""
        # Read implementation
        
    async def _plan(
        self, ctx: ResourceContext[ExampleConfig, ExampleState]
    ) -> tuple[ExampleState, bytes]:
        """Plan resource changes."""
        # Plan implementation
        
    async def _apply(
        self, ctx: ResourceContext[ExampleConfig, ExampleState]
    ) -> tuple[ExampleState, bytes]:
        """Apply resource changes."""
        # Apply implementation
```

5.2. State Management

   State management is a critical aspect of resource implementation.
   Resources MUST properly handle state transitions and persistence.

5.2.1. State Types

   Resources SHOULD define explicit state types for type safety:

```python
@attrs.define(frozen=True)
class ServerState:
    """State representation of server resource."""
    id: str = attrs.field()
    name: str = attrs.field()
    instance_type: str = attrs.field()
    region: str = attrs.field()
    status: str = attrs.field()
    tags: Dict[str, str] = attrs.field(factory=dict)
    enabled: bool = attrs.field(default=True)
```

5.2.2. Config Types

   Resources SHOULD define explicit configuration types for type safety:

```python
@attrs.define(frozen=True)
class ServerConfig:
    """Configuration for server resource."""
    name: str = attrs.field()
    instance_type: str = attrs.field()
    region: str = attrs.field()
    tags: Dict[str, str] = attrs.field(factory=dict)
    enabled: bool = attrs.field(default=True)
    
    @name.validator
    def _validate_name(self, attribute, value):
        """Validate name format."""
        if not value:
            raise ValueError("Name cannot be empty")
        if not re.match(r'^[a-zA-Z0-9_-]+$', value):
            raise ValueError("Name can only contain letters, numbers, underscores, and hyphens")
```

5.2.3. State Diffing

   Resources SHOULD implement state diffing to determine changes:

```python
def diff_state(current: Optional[State], planned: State) -> dict[str, tuple[Any, Any]]:
    """Compute differences between current and planned state."""
    changes = {}
    
    if current is None:
        # Resource is being created, all fields are new
        return {field: (None, getattr(planned, field)) for field in fields(planned)}
    
    # Check each field for changes
    for field in fields(planned):
        current_value = getattr(current, field.name)
        planned_value = getattr(planned, field.name)
        
        if current_value != planned_value:
            changes[field.name] = (current_value, planned_value)
    
    return changes
```

5.3. Context Model

   The ResourceContext provides a consistent way to pass configuration
   and state information to resource operations. This model ensures that
   all necessary information is available for each operation.

5.3.1. ResourceContext Definition

```python
@dataclass(frozen=True)
class ResourceContext(Generic[ConfigType, StateType]):
    """Context for resource operations."""
    config: ConfigType
    state: Optional[StateType] = None
    planned_state: Optional[StateType] = None
    private: Optional[bytes] = None
```

5.3.2. Context Usage

   Resource operations MUST use the ResourceContext for accessing
   configuration and state information:

```python
async def _read(self, ctx: ResourceContext[ServerConfig, ServerState]) -> ServerState:
    """Read current server state."""
    # Access configuration
    region = ctx.config.region
    name = ctx.config.name
    
    # Access current state (if available)
    if ctx.state:
        server_id = ctx.state.id
    else:
        server_id = None
    
    # Implementation logic...
    
    return state

async def _plan(
    self, ctx: ResourceContext[ServerConfig, ServerState]
) -> tuple[ServerState, bytes]:
    """Plan server changes."""
    # Determine if creating new resource
    creating = ctx.state is None
    
    # Create planned state based on config and current state
    planned_state = ServerState(
        id=ctx.state.id if ctx.state else f"srv-{ctx.config.name}",
        name=ctx.config.name,
        # Other fields...
    )
    
    # Return planned state and private data
    return planned_state, b""

async def _apply(
    self, ctx: ResourceContext[ServerConfig, ServerState]
) -> tuple[ServerState, bytes]:
    """Apply server changes."""
    # Determine operation type
    creating = ctx.state is None
    deleting = ctx.planned_state is None
    
    if creating:
        # Create resource
        # ...
    elif deleting:
        # Delete resource
        # ...
    else:
        # Update resource
        # ...
    
    # Return new state and private data
    return new_state, b""
```

6. Protocol Integration

   Protocol integration is the bridge between Pyvider's component model
   and Terraform's gRPC-based plugin protocol. This integration MUST
   handle all required RPCs, type conversions, and error reporting.

6.1. Protocol Handlers

   Protocol handlers MUST implement all required RPCs from the Terraform
   Plugin Protocol v6. Each handler MUST properly decode requests,
   delegate to appropriate components, and encode responses.

6.1.1. Handler Interface

   Protocol handlers SHOULD follow a consistent interface:

```python
async def ProtocolHandler(request, context) -> Response:
    """Handle protocol requests."""
    try:
        # Extract request details
        # ...
        
        # Delegate to appropriate component
        # ...
        
        # Encode and return response
        # ...
    except Exception as e:
        # Handle error
        return Response(
            diagnostics=[
                Diagnostic(
                    severity=Diagnostic.ERROR,
                    summary="Handler error",
                    detail=str(e)
                )
            ]
        )
```

6.1.2. Core Protocol Handlers

   The following core protocol handlers MUST be implemented:

   1. GetMetadata: Provider discovery and capabilities
   2. GetProviderSchema: Schema discovery for provider, resources, data sources
   3. ValidateResourceConfig: Validate resource configuration
   4. ReadResource: Read resource state
   5. PlanResourceChange: Plan resource changes
   6. ApplyResourceChange: Apply resource changes
   7. Capabilities (as defined by provider): mTLS, state import, etc.

Example GetProviderSchema handler:

```python
async def GetProviderSchemaHandler(request, context) -> pb.GetProviderSchema.Response:
    """Handle GetProviderSchema requests."""
    try:
        # Track errors during schema collection
        schema_errors = []
        
        # Initialize schema collections
        resource_schemas = {}
        data_source_schemas = {}
        function_schemas = {}
        diagnostics = []

        # Get provider schema
        provider_schema = get_provider_schema()
        provider_proto_schema = schema_to_proto(provider_schema)

        # Collect resource schemas from registry
        if "resource" in hub.registry:
            for name, resource_class in hub.registry["resource"].items():
                try:
                    resource_instance = resource_class()
                    if hasattr(resource_instance, "get_schema"):
                        schema = resource_instance.get_schema()
                        proto_schema = schema_to_proto(schema)
                        resource_schemas[name] = proto_schema
                except Exception as e:
                    error_msg = f"Failed to get schema for resource {name}: {e}"
                    schema_errors.append(error_msg)

        # Similar logic for data sources and functions...
        
        # Create diagnostics from errors
        for error in schema_errors:
            diagnostics.append(
                Diagnostic(
                    severity=Diagnostic.WARNING,
                    summary="Schema collection warning",
                    detail=error
                )
            )

        # Return response
        return pb.GetProviderSchema.Response(
            provider=provider_proto_schema,
            resource_schemas=resource_schemas,
            data_source_schemas=data_source_schemas,
            functions=function_schemas,
            diagnostics=diagnostics,
            server_capabilities=ServerCapabilities(
                plan_destroy=True,
                get_provider_schema_optional=False,
                move_resource_state=True
            )
        )
    except Exception as e:
        return pb.GetProviderSchema.Response(
            diagnostics=[
                Diagnostic(
                    severity=Diagnostic.ERROR,
                    summary="GetProviderSchema error",
                    detail=str(e)
                )
            ]
        )
```

6.1.3. Resource Handlers

   Resource handlers MUST delegate to appropriate resource implementations:

Example ReadResource handler:

```python
async def ReadResourceHandler(request, context) -> pb.ReadResource.Response:
    """Handle ReadResource requests."""
    try:
        # Extract resource type and current state from request
        resource_type = request.type_name
        if not resource_type:
            return pb.ReadResource.Response(
                diagnostics=[
                    Diagnostic(
                        severity=Diagnostic.ERROR,
                        summary="Invalid request",
                        detail="Resource type name is missing"
                    )
                ]
            )

        # Get resource implementation from registry
        resource_class = hub.get_component("resource", resource_type)
        if not resource_class:
            return pb.ReadResource.Response(
                diagnostics=[
                    Diagnostic(
                        severity=Diagnostic.ERROR,
                        summary="Resource not found",
                        detail=f"Resource type '{resource_type}' not registered"
                    )
                ]
            )

        # Decode current state
        current_state = decode_dynamic_value(request.current_state)

        # Create resource context
        resource_context = ResourceContext(
            config=None,  # No config needed for read
            state=current_state,
            private=request.private
        )

        # Call read method on resource
        resource_instance = resource_class()
        new_state = await resource_instance.read(resource_context)

        # Encode new state
        encoded_state = encode_dynamic_value(new_state)

        # Return response
        return pb.ReadResource.Response(
            new_state=encoded_state,
            diagnostics=[]
        )
    except Exception as e:
        return pb.ReadResource.Response(
            diagnostics=[
                Diagnostic(
                    severity=Diagnostic.ERROR,
                    summary="Read operation failed",
                    detail=str(e)
                )
            ]
        )
```

6.1.4. Function Handlers

   Function handlers MUST delegate to registered functions:

Example CallFunction handler:

```python
async def CallFunctionHandler(request, context) -> pb.CallFunction.Response:
    """Handle CallFunction requests."""
    try:
        # Extract function name and arguments
        func_name = request.name
        if not func_name:
            return pb.CallFunction.Response(
                error=FunctionError(
                    text="Function name is required"
                )
            )

        # Find function in registry
        function = hub.get_component("function", func_name)
        if not function:
            return pb.CallFunction.Response(
                error=FunctionError(
                    text=f"Function '{func_name}' not registered"
                )
            )

        # Decode arguments
        args = [decode_dynamic_value(arg) for arg in request.arguments]

        # Call function
        if asyncio.iscoroutinefunction(function):
            result = await function(*args)
        else:
            result = function(*args)

        # Encode result
        encoded_result = encode_dynamic_value(result)

        # Return response
        return pb.CallFunction.Response(
            result=encoded_result
        )
    except Exception as e:
        return pb.CallFunction.Response(
            error=FunctionError(
                text=str(e)
            )
        )
```

6.2. Type Conversion

   Type conversion is a critical component of protocol integration. The
   framework MUST provide robust conversion between Pyvider's type system
   and Terraform's protocol types.

6.2.1. Dynamic Value Encoding/Decoding

   The framework MUST provide utilities for encoding and decoding
   dynamic values:

```python
def encode_dynamic_value(value: Any) -> pb.DynamicValue:
    """Encode a value as a DynamicValue."""
    if value is None:
        return pb.DynamicValue(null=True)
    
    # Convert value to JSON
    json_data = json.dumps(value).encode("utf-8")
    
    # Return dynamic value
    return pb.DynamicValue(json=json_data)

def decode_dynamic_value(dv: pb.DynamicValue) -> Any:
    """Decode a DynamicValue to a Python value."""
    if dv.null:
        return None
    
    if dv.json:
        # Decode JSON data
        return json.loads(dv.json.decode("utf-8"))
    
    if dv.msgpack:
        # Decode MessagePack data (if supported)
        import msgpack
        return msgpack.unpackb(dv.msgpack)
    
    # Unknown format
    raise ValueError("Unknown DynamicValue format")
```

6.2.2. Schema Type Conversion

   The framework MUST provide utilities for converting between Pyvider's
   schema types and Terraform's protocol types:

```python
def get_proto_type_bytes(value: Any) -> bytes:
    """Get protocol type bytes for a schema type."""
    # For SchemaType instances
    if hasattr(value, "proto_value"):
        return value.proto_value
        
    # For string type names
    if isinstance(value, str):
        type_map = {
            "string": b'"string"',
            "number": b'"number"',
            "bool": b'"bool"',
            "list": b'"list"',
            "map": b'"map"',
            "set": b'"set"',
            "object": b'"object"',
            "dynamic": b'"dynamic"'
        }
        value_lower = value.lower()
        if value_lower in type_map:
            return type_map[value_lower]
            
    # For Cty type instances
    if hasattr(value, "__class__"):
        class_name = value.__class__.__name__
        type_map = {
            "CtyString": b'"string"',
            "CtyNumber": b'"number"',
            "CtyBool": b'"bool"',
            "CtyList": b'"list"',
            "CtyMap": b'"map"',
            "CtySet": b'"set"',
            "CtyObject": b'"object"',
            "CtyDynamic": b'"dynamic"'
        }
        if class_name in type_map:
            return type_map[class_name]
    
    # Default to dynamic type
    return b'"dynamic"'
```

6.2.3. Element Type Handling

   The framework MUST handle element types for collection types:

```python
def format_collection_type(container_type: str, element_type_str: str) -> bytes:
    """Format a collection type with element type."""
    # Remove quotes from element type string
    element_type_str = element_type_str.strip('"')
    
    # Format as collection(element_type)
    formatted_type = f'{container_type}({element_type_str})'
    
    # Add JSON quotes and encode to bytes
    return f'"{formatted_type}"'.encode('utf-8')

def get_element_type_bytes(attr_type: Any) -> Optional[bytes]:
    """Get element type bytes for a collection type."""
    # For Cty collection types
    if hasattr(attr_type, "__class__"):
        class_name = attr_type.__class__.__name__
        
        # Map type
        if class_name == "CtyMap" and hasattr(attr_type, "value_type"):
            return get_proto_type_bytes(attr_type.value_type)
            
        # List or set type
        if class_name in ("CtyList", "CtySet") and hasattr(attr_type, "element_type"):
            return get_proto_type_bytes(attr_type.element_type)
    
    # For schema types with element_type
    if hasattr(attr_type, "element_type") and attr_type.element_type is not None:
        return get_proto_type_bytes(attr_type.element_type)
    
    # Default to string
    return b'"string"'
```

6.3. Protocol Security

   The framework MUST implement proper security measures for the
   Terraform plugin protocol, including:

   1. Magic Cookie Validation: Validate the Terraform plugin protocol cookie
   2. Mutual TLS (mTLS): Secure gRPC communication
   3. Sensitive Data Handling: Proper handling of sensitive values

6.3.1. Magic Cookie Validation

```python
def validate_magic_cookie(cookie: str) -> bool:
    """Validate the Terraform plugin protocol magic cookie."""
    expected_cookie = "d602bf8f470bc67ca7faa0386276bbdd4330efaf76d1a219cb4d6991ca9872b2"
    return cookie == expected_cookie
```

6.3.2. Mutual TLS Configuration

```python
def configure_mtls(server, cert_path: str, key_path: str) -> None:
    """Configure mutual TLS for the gRPC server."""
    # Load server credentials
    with open(cert_path, 'rb') as f:
        certificate_chain = f.read()
    with open(key_path, 'rb') as f:
        private_key = f.read()
    
    # Create server credentials
    server_credentials = grpc.ssl_server_credentials(
        [(private_key, certificate_chain)],
        root_certificates=None,
        require_client_auth=True
    )
    
    # Secure the server
    server.add_secure_port('[::]:{port}', server_credentials)
```

6.3.3. Sensitive Data Handling

```python
def handle_sensitive_value(value: Any, sensitive: bool) -> Any:
    """Handle sensitive values in logs and error messages."""
    if not sensitive:
        return value
    
    # Mask sensitive values in logs and errors
    if isinstance(value, str):
        return "(sensitive)"
    elif isinstance(value, dict):
        return {k: handle_sensitive_value(v, True) for k, v in value.items()}
    elif isinstance(value, list):
        return [handle_sensitive_value(v, True) for v in value]
    else:
        return "(sensitive)"
```

